{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Blog\n",
    "https://miroslawmamczur.pl/wykrywanie-twarzy-real-time-w-15-liniach-kodu-w-python/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python --version #command line tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from platform import python_version\n",
    "print(python_version())\n",
    "print(\"* * * * *\")\n",
    "\n",
    "import sys\n",
    "print(\"SYS.VERSION:\", sys.version)\n",
    "print(\"SYS.EXECUTABLE:\", sys.executable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wczytanie bibliotek i modelu\n",
    "[haarcascades on Github](https://github.com/opencv/opencv/tree/master/data/haarcascades)\n",
    "\n",
    "Whole opencv repo ~91MB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-10T15:11:21.012699Z",
     "start_time": "2020-06-10T15:11:20.852608Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "print(np.__version__)\n",
    "print(cv2.__version__)\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_alt2.xml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1 - przechwytywanie Video\n",
    "[OpenCV Getting Started with Videos](https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_gui/py_video_display/py_video_display.html#getting-started-with-videos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-10T15:13:08.396877Z",
     "start_time": "2020-06-10T15:11:21.949240Z"
    }
   },
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "while(True):\n",
    "    ret, img = cap.read()\n",
    "    cv2.imshow('img',img)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'): \n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-05T17:11:52.469106Z",
     "start_time": "2020-06-05T17:11:52.461620Z"
    }
   },
   "source": [
    "### Detekcja twarzy (kamera online)\n",
    "Ogólnie obrazy, które widzimy, mają postać kanału RGB (czerwony, zielony, niebieski). Szary kanał jest łatwy do przetworzenia i jest mniej intensywny obliczeniowo, ponieważ zawiera tylko 1 kanał czarno-biały. Dodatkowo wczytane modele działają znacznie lepiej na odcieniach szarości.\n",
    "\n",
    "`gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)`\n",
    "\n",
    "Mamy przechwycony obraz w odcieniu szarości. Teraz spróbujmy zlokalizować położenie twarzy na tym obrazie. Wykorzystamy wbudowaną funkcję **detectMultiScale** z załadowanego naszego obiektu **face_cascade**, która pomoże znaleźć wszystkie lokalizacje twarzy. Można to zrobić w ten sposób:\n",
    "\n",
    "`faces = face_cascade.detectMultiScale(gray, scaleFactor=1.05, minNeighbors=5, minSize=(50,50))`\n",
    "\n",
    "Wywołując ją warto podać cztery parametry:\n",
    "* **image** – pierwszy (jedyny obligo) to nasz obraz\n",
    "* **scaleFactor** – wytrenowany model Haar Cascade ma zdefiniowany rozmiar twarzy, która jest wykrywana na obrazie. Jednak przeskalowując obraz wejściowy, możesz zmienić rozmiar większej twarzy na mniejszą, dzięki czemu algorytm może ją wykryć. Ustalenie tego parametru na wartość scaleFactor = 1.05 oznacza zmniejszenie rozmiaru wejściowego o 5%, co zwiększa szansę na wykrycie twarzy przez model. Im większa wartość tym jakość wykrytych obiektów jest wyższa.\n",
    "* **minNeighbors** – minimalna liczba sąsiadujących obszarów, które zaklasyfikowano jako posiadający porządany obiekt. Ten parametr wpływa na jakość wykrytych twarzy. Wyższa wartość powoduje mniej wykrywalności, ale o wyższej jakości.\n",
    "* **minSize** – minimalny rozmiar obszaru posiadający pożądany obiekt.\n",
    "\n",
    "Z powyższego kroku funkcja **detectMultiScale** zwraca 4 wartości – współrzędną x, współrzędną y, szerokość (w) i wysokość (h) wykrytych cechy twarzy. Na podstawie tych 4 wartości narysujemy prostokąt wokół twarzy.\n",
    "\n",
    "`for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(190,0,0),2)`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-10T15:14:26.006330Z",
     "start_time": "2020-06-10T15:13:12.231888Z"
    }
   },
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while(True):\n",
    "    ret, img = cap.read()\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.05, minNeighbors=5, minSize=(50,50))\n",
    "\n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(190,0,0),2)\n",
    "\n",
    "    cv2.imshow('img',img)\n",
    "    if cv2.waitKey(30) & 0xFF == ord('q'): \n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Całość w 15 linijek (kamera online)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-05T17:47:45.554434Z",
     "start_time": "2020-06-05T17:47:26.633317Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_alt2.xml')\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while(True):\n",
    "    ret, img = cap.read()\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.05, minNeighbors=5, minSize=(50,50))\n",
    "\n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(190,0,0),2)\n",
    "\n",
    "    cv2.imshow('img',img)\n",
    "    if cv2.waitKey(30) & 0xFF == ord('q'): \n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dodanie efektu rozmazania (kamera online)\n",
    "Teraz ogranicza Was już tylko wyobraźnia co zrobicie z zdjęciem twarzy. Wykrywanie twarzy mamy już rozpracowane. Możecie w prosty sposób napisać mechanizm do zamazywania twarzy. Wystarczy do powyższego kodu zamiast prostokąta wstawić funkcję blur do rozmazywania i to wszystko\n",
    "```python\n",
    "    for (x,y,w,h) in faces:        \n",
    "        face = img[y:y+h, x:x+w]\n",
    "        face = cv2.blur(face,((w // 5),(h // 5)))\n",
    "        img[y:y+h, x:x+w] = face\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-10T15:21:10.445743Z",
     "start_time": "2020-06-10T15:18:25.368698Z"
    }
   },
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while(True):\n",
    "    ret, img = cap.read()\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.05, minNeighbors=5, minSize=(50,50))\n",
    "\n",
    "    for (x,y,w,h) in faces:        \n",
    "        face = img[y:y+h, x:x+w] #cropping recognized face\n",
    "        face = cv2.blur(face,((w // 5),(h // 5))) #blurring recognized face\n",
    "        img[y:y+h, x:x+w] = face #adding blurred recognized face to output image\n",
    "\n",
    "    cv2.imshow('img',img)\n",
    "    if cv2.waitKey(30) & 0xFF == ord('q'): \n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wykrywanie dodatkowo oczu i uśmiechu (kamera online)\n",
    "uwaga, trzeba było mocniej dobrać \"sąsiadów\" dla usmiechu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-10T15:18:17.370320Z",
     "start_time": "2020-06-10T15:15:26.435720Z"
    }
   },
   "outputs": [],
   "source": [
    "eye_cascade = cv2.CascadeClassifier('haarcascade_eye.xml')\n",
    "smile_cascade = cv2.CascadeClassifier('haarcascade_smile.xml')\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while(True):\n",
    "    ret, img = cap.read()\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.05, minNeighbors=5, minSize=(50,50))\n",
    "\n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(190,0,0),2)\n",
    "        roi_gray = gray[y:y+h, x:x+w]\n",
    "        roi_color = img[y:y+h, x:x+w]\n",
    "        \n",
    "        eyes = eye_cascade.detectMultiScale(roi_gray)\n",
    "        for (ex,ey,ew,eh) in eyes:\n",
    "            cv2.rectangle(roi_color,(ex,ey),(ex+ew,ey+eh),(0,190,0),2)\n",
    "            \n",
    "        smile = smile_cascade.detectMultiScale(roi_gray,1.5,15)\n",
    "        for (sx,sy,sw,sh) in smile:\n",
    "            cv2.rectangle(roi_color,(sx,sy),(sx+sw,sy+sh),(0,0,190),2)\n",
    "\n",
    "    cv2.imshow('img',img)\n",
    "    if cv2.waitKey(30) & 0xFF == ord('q'): \n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wykrywanie dodatkowo oczu i uśmiechu (z filmu video i zapisanie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-06T17:45:48.759129Z",
     "start_time": "2020-06-06T17:45:36.003567Z"
    }
   },
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture('TWOJ PLIK.mp4')\n",
    "\n",
    "while(True):\n",
    "    ret, img = cap.read()\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.05, minNeighbors=5, minSize=(50,50))\n",
    "\n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(190,0,0),2)\n",
    "        roi_gray = gray[y:y+h, x:x+w]\n",
    "        roi_color = img[y:y+h, x:x+w]\n",
    "        \n",
    "        eyes = eye_cascade.detectMultiScale(roi_gray)\n",
    "        for (ex,ey,ew,eh) in eyes:\n",
    "            cv2.rectangle(roi_color,(ex,ey),(ex+ew,ey+eh),(0,190,0),2)\n",
    "            \n",
    "        smile = smile_cascade.detectMultiScale(roi_gray,1.5,15)\n",
    "        for (sx,sy,sw,sh) in smile:\n",
    "            cv2.rectangle(roi_color,(sx,sy),(sx+sw,sy+sh),(0,0,190),2)\n",
    "\n",
    "    cv2.imshow('img',img)\n",
    "    out.write(img)\n",
    "    if cv2.waitKey(5) & 0xFF == ord('q'): \n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
